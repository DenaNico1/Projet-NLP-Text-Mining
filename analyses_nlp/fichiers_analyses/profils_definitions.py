"""
D√©finitions des Profils M√©tier - VERSION v2 FINALE
14 profils Data/IA dont "Data/IA - Non sp√©cifi√©" (profil fourre-tout)

NOUVEAUT√âS v2:
- Profil #14: "Data/IA - Non sp√©cifi√©" (capture reste avec seuil 1.5)
- Seuils optimis√©s
- Variantes enrichies

R√©sultat attendu: 85-90% classification

Auteur: Projet NLP Text Mining
Date: D√©cembre 2025
"""

# Configuration globale
CLASSIFICATION_CONFIG = {
    'min_score': 4.5,
    'min_confidence': 0.55,
    'weights': {
        'title': 0.6,
        'description': 0.2,
        'competences': 0.2
    }
}

# Profils stricts
STRICT_PROFILES = [
    'AI Engineer',
    'AI Research Scientist',
    'Computer Vision Engineer'
]

# Profils permissifs
PERMISSIVE_PROFILES = [
    'Data Analyst',
    'Data Consultant',
    'Data Manager',
    'Data/IA - Non sp√©cifi√©'  # ‚úÖ NOUVEAU
]


# ============================================
# PROFILS 1-13 : IDENTIQUES √Ä v1_optimized
# ============================================

PROFILS = {
    
    # [Tous les profils 1-13 de v1_optimized...]
    # Je vais les copier depuis v1_optimized
    
    'Data Engineer': {
        'description': 'Pipelines donn√©es, ETL, Big Data, Architecte Data, cloud',
        'title_variants': [
            'data engineer', 'engineer data', 'data engineering',
            'ing√©nieur donn√©es', 'ingenieur donnees',
            'ing√©nieur data', 'ingenieur data',
            'big data',
            'ing√©nieur big data', 'ingenieur big data',
            'd√©veloppeur big data', 'developpeur big data',
            'big data engineer', 'big data developer',
            'lead data engineer',
            'lead engineer data',
            'tech lead data engineer',
            'senior data engineer',
            'architecte data', 'architecte donn√©es', 'architecte donnees',
            'data architect',
            'd√©veloppeur data', 'developpeur data',
            'data ing√©nieur', 'data ingenieur',
            'ing√©nieur support data', 'ingenieur support data',
            'ing√©nieur etl', 'ingenieur etl',
            'etl engineer', 'etl developer',
            'cloud data engineer'
        ],
        'keywords_title': [
            'pipeline', 'etl', 'elt',
            'big data', 'warehouse',
            'cloud', 'plateforme',
            'architecte', 'architect',
            'lead'
        ],
        'keywords_strong': [
            'airflow', 'kafka', 'spark',
            'hadoop', 'hive',
            'data lake', 'lakehouse',
            'dbt', 'streaming'
        ],
        'competences_core': [
            'sql', 'python', 'airflow', 'spark',
            'aws', 'data engineer', 'big data'
        ],
        'competences_tech': [
            'kafka', 'docker', 'kubernetes',
            'postgresql', 'mongodb'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.2,
            'competences': 0.2
        }
    },
    
    'Data Scientist': {
        'description': 'ML classique, statistiques, mod√®les pr√©dictifs',
        'title_variants': [
            'data scientist', 'scientist data',
            'data science engineer',
            'scientifique donn√©es', 'scientifique de donn√©es',
            'scientist', 'scientifique',
            'statisticien', 'statisticienne',
            'charg√© √©tudes statistiques', 'charge etudes statistiques',
            'charg√©e √©tudes statistiques', 'chargee etudes statistiques',
            'analyste statistique',
            'ml scientist', 'machine learning scientist',
            'consultant data scientist',
            'consultante data scientist'
        ],
        'keywords_title': [
            'machine learning', 'ml',
            'statistiques', 'statisticien',
            'pr√©dictif', 'predictive',
            'mod√®le', 'scientist'
        ],
        'keywords_strong': [
            'scikit-learn', 'sklearn',
            'r√©gression', 'classification',
            'pr√©diction', 'prediction',
            'xgboost', 'lightgbm'
        ],
        'competences_core': [
            'machine learning', 'python', 'scikit-learn',
            'statistiques', 'r'
        ],
        'competences_tech': [
            'pandas', 'numpy', 'jupyter',
            'matplotlib', 'seaborn', 'sql'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.2,
            'competences': 0.2
        }
    },
    
    'Data Analyst': {
        'description': 'Analyse exploratoire, SQL, Excel, reporting',
        'title_variants': [
            'data analyst', 'analyste donn√©es', 'analyste de donn√©es',
            'analyst data', 'analyste data',
            'junior data analyst',
            'analyste', 'analyst',
            'data analysis',
            'senior data analyst',
            'lead data analyst'
        ],
        'keywords_title': [
            'analyse', 'analysis',
            'sql', 'excel',
            'reporting',
            'senior'
        ],
        'keywords_strong': [
            'analyse exploratoire',
            'data cleaning',
            'statistiques descriptives',
            'kpi', 'metrics'
        ],
        'competences_core': [
            'sql', 'excel', 'analyse',
            'python'
        ],
        'competences_tech': [
            'pandas', 'sql', 'excel',
            'power bi', 'tableau'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.2,
            'competences': 0.2
        }
    },
    
    'BI Analyst': {
        'description': 'Business Intelligence, dashboards, reporting, business analyst',
        'title_variants': [
            'bi analyst', 'business intelligence analyst',
            'analyste bi', 'analyste business intelligence',
            'business analyst',
            'business analyst data',
            'business analyst (h/f)',
            'business analyst f/h',
            'analyste business',
            'analyste affaires',
            'ba data',
            'analyste m√©tier', 'analyste metier',
            'd√©veloppeur bi', 'developpeur bi',
            'bi developer', 'business intelligence developer',
            'analyste d√©cisionnel', 'analyste decisionnel',
            'd√©veloppeur d√©cisionnel', 'developpeur decisionnel',
            'business developer data',
            'business developer',
            'tableau analyst', 'power bi analyst',
            'tableau developer', 'power bi developer'
        ],
        'keywords_title': [
            'tableau', 'power bi', 'powerbi',
            'looker', 'qlik',
            'bi', 'business intelligence',
            'd√©cisionnel', 'decisionnel',
            'dashboard',
            'business analyst'
        ],
        'keywords_strong': [
            'dashboard', 'reporting',
            'visualisation donn√©es',
            'data visualization', 'dataviz',
            'kpi', 'metrics',
            'dax', 'powerquery'
        ],
        'competences_core': [
            'power bi', 'tableau', 'sql',
            'excel', 'looker',
            'business analysis'
        ],
        'competences_tech': [
            'dax', 'powerquery', 'qlik',
            'sql', 'excel'
        ],
        'weights': {
            'title': 0.65,
            'description': 0.15,
            'competences': 0.2
        }
    },
    
    'Data Consultant': {
        'description': 'Conseil Data, transformation, accompagnement client',
        'title_variants': [
            'consultant data', 'data consultant',
            'consultant', 'consultante',
            'conseil data',
            'consulting data',
            'consultant data engineer',
            'consultante data engineer'
        ],
        'keywords_title': [
            'consultant', 'conseil',
            'consulting',
            'transformation',
            'advisory'
        ],
        'keywords_strong': [
            'transformation digitale',
            'accompagnement',
            'client', 'mission',
            'esn', 'cabinet'
        ],
        'competences_core': [
            'conseil', 'transformation',
            'management', 'gestion projet'
        ],
        'competences_tech': [
            'python', 'sql', 'excel',
            'power bi'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.25,
            'competences': 0.15
        }
    },
    
    'Data Manager': {
        'description': 'Management √©quipe data, chef projet data, CDO, direction',
        'title_variants': [
            'data manager', 'manager data',
            'responsable data', 'responsable donn√©es', 'responsable donnees',
            'team lead data', 'lead data',
            'chef de projet data', 'chef projet data',
            'chef de projets moa data',
            'chef projet moa data',
            'product manager data', 'pm data',
            'product owner data', 'po data',
            'chief data officer', 'cdo',
            'directeur data', 'directrice data',
            'directeur data ai', 'directrice data ai',
            'directeur data ai factory', 'directrice data ai factory',
            'head of data', 'data director'
        ],
        'keywords_title': [
            'manager', 'responsable',
            'chef', 'director', 'directeur', 'directrice',
            'lead', 'head', 'cdo',
            'product', 'po', 'pm',
            'moa'
        ],
        'keywords_strong': [
            'management', '√©quipe', 'team',
            'projet', 'product',
            'strat√©gie', 'gouvernance',
            'roadmap', 'transformation',
            'factory'
        ],
        'competences_core': [
            'management', 'gestion projet',
            'leadership', 'strat√©gie'
        ],
        'competences_tech': [
            'sql', 'python', 'agile',
            'jira', 'scrum'
        ],
        'weights': {
            'title': 0.65,
            'description': 0.2,
            'competences': 0.15
        }
    },
    
    'Data Architect': {
        'description': 'Architecture donn√©es, gouvernance, strat√©gie senior',
        'title_variants': [
            'data architect', 'architecte donn√©es', 'architecte donnees',
            'architect data',
            'data architect (h/f)',
            'architecte si data',
            'si data architect',
            'architecte solution data',
            'solution architect data',
            'chief data architect',
            'lead architect',
            'data architect confirm√©', 'data architect confirme'
        ],
        'keywords_title': [
            'architecture', 'architect',
            'gouvernance', 'governance',
            'strat√©gie', 'strategy',
            'solution'
        ],
        'keywords_strong': [
            'data architecture',
            'enterprise architecture',
            'data modeling',
            'master data management', 'mdm',
            'data catalog'
        ],
        'competences_core': [
            'architecture', 'gouvernance',
            'data modeling', 'sql'
        ],
        'competences_tech': [
            'sql', 'cloud', 'aws', 'azure',
            'databricks'
        ],
        'weights': {
            'title': 0.65,
            'description': 0.2,
            'competences': 0.15
        }
    },
    
    'AI Engineer': {
        'description': 'IA g√©n√©rative, LLMs, NLP avanc√©, transformers',
        'title_variants': [
            'ai engineer', 'ing√©nieur ia', 'ingenieur ia',
            'engineer ai', 'ia engineer',
            'artificial intelligence engineer',
            'llm engineer', 'nlp engineer',
            'tech lead ia', 'tech lead ai',
            'lead ai engineer', 'lead ia engineer',
            'chef de projet ia', 'chef projet ia',
            'chef de projet technique ia'
        ],
        'keywords_title': [
            'llm', 'llms',
            'gpt', 'chatgpt',
            'transformers', 'bert',
            'nlp', 'generative',
            'ia g√©n√©rative', 'generative ai',
            'tech lead'
        ],
        'keywords_strong': [
            'langchain', 'llamaindex',
            'rag', 'retrieval augmented',
            'prompt engineering',
            'fine-tuning',
            'hugging face',
            'chatbot', 'embedding'
        ],
        'competences_core': [
            'intelligence artificielle', 'llm',
            'transformers', 'gpt', 'langchain', 'nlp'
        ],
        'competences_tech': [
            'python', 'pytorch', 'tensorflow',
            'hugging face', 'api'
        ],
        'weights': {
            'title': 0.65,
            'description': 0.2,
            'competences': 0.15
        }
    },
    
    'ML Engineer': {
        'description': 'MLOps, d√©ploiement ML, production, pipelines ML',
        'title_variants': [
            'ml engineer', 'machine learning engineer',
            'ing√©nieur ml', 'ingenieur ml',
            'engineer ml',
            'mlops engineer', 'ml ops engineer'
        ],
        'keywords_title': [
            'mlops', 'ml ops',
            'd√©ploiement', 'deployment',
            'production',
            'devops ml'
        ],
        'keywords_strong': [
            'mlflow', 'kubeflow',
            'model deployment',
            'kubernetes', 'docker',
            'ci/cd ml'
        ],
        'competences_core': [
            'mlops', 'ci/cd', 'kubernetes', 'docker',
            'machine learning'
        ],
        'competences_tech': [
            'mlflow', 'kubeflow', 'tensorflow',
            'pytorch', 'git', 'linux'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.2,
            'competences': 0.2
        }
    },
    
    'Analytics Engineer': {
        'description': 'Transformation donn√©es, dbt, SQL avanc√©, analytics',
        'title_variants': [
            'analytics engineer',
            'ing√©nieur analytics', 'ingenieur analytics',
            'dbt engineer'
        ],
        'keywords_title': [
            'analytics', 'dbt',
            'transformation', 'sql'
        ],
        'keywords_strong': [
            'data modeling',
            'data transformation',
            'looker', 'metabase'
        ],
        'competences_core': [
            'dbt', 'sql', 'python',
            'data modeling'
        ],
        'competences_tech': [
            'git', 'postgresql', 'snowflake',
            'databricks'
        ],
        'weights': {
            'title': 0.6,
            'description': 0.2,
            'competences': 0.2
        }
    },
    
    'MLOps Engineer': {
        'description': 'DevOps pour ML, CI/CD ML, infrastructure ML',
        'title_variants': [
            'mlops engineer', 'ml ops engineer',
            'ing√©nieur mlops', 'ingenieur mlops',
            'devops ml'
        ],
        'keywords_title': [
            'mlops', 'ml ops',
            'devops',
            'kubernetes', 'k8s'
        ],
        'keywords_strong': [
            'ci/cd', 'terraform',
            'infrastructure as code',
            'monitoring'
        ],
        'competences_core': [
            'mlops', 'kubernetes', 'docker',
            'ci/cd', 'devops'
        ],
        'competences_tech': [
            'terraform', 'git', 'linux',
            'aws', 'azure'
        ],
        'weights': {
            'title': 0.65,
            'description': 0.15,
            'competences': 0.2
        }
    },
    
    'AI Research Scientist': {
        'description': 'Recherche IA, publications, PhD, innovation',
        'title_variants': [
            'research scientist', 'chercheur',
            'researcher', 'scientifique recherche',
            'ai researcher', 'ml researcher',
            'research engineer'
        ],
        'keywords_title': [
            'research', 'recherche',
            'phd', 'doctorat',
            'chercheur', 'postdoc'
        ],
        'keywords_strong': [
            'publication', 'paper',
            'conference', 'neurips', 'icml',
            'innovation'
        ],
        'competences_core': [
            'recherche', 'intelligence artificielle',
            'machine learning', 'deep learning'
        ],
        'competences_tech': [
            'python', 'pytorch', 'tensorflow',
            'jupyter'
        ],
        'weights': {
            'title': 0.7,
            'description': 0.15,
            'competences': 0.15
        }
    },
    
    'Computer Vision Engineer': {
        'description': 'Vision par ordinateur, images, vid√©o, CNN',
        'title_variants': [
            'computer vision engineer',
            'ing√©nieur computer vision', 'ingenieur computer vision',
            'cv engineer',
            'vision engineer',
            'image processing engineer'
        ],
        'keywords_title': [
            'computer vision', 'vision',
            'image', 'vid√©o', 'video',
            'opencv', 'cv'
        ],
        'keywords_strong': [
            'cnn', 'convolutional',
            'yolo', 'mask r-cnn',
            'object detection',
            'image segmentation'
        ],
        'competences_core': [
            'computer vision', 'deep learning',
            'opencv', 'pytorch'
        ],
        'competences_tech': [
            'python', 'opencv', 'cuda',
            'tensorflow'
        ],
        'weights': {
            'title': 0.7,
            'description': 0.15,
            'competences': 0.15
        }
    },
    
    # ========================================
    # 14. DATA/IA - NON SP√âCIFI√â (NOUVEAU)
    # ========================================
    'Data/IA - Non sp√©cifi√©': {
        'description': 'Postes Data/IA sans informations suffisantes pour classification pr√©cise',
        
        # ‚úÖ Capture TOUT ce qui contient data/ia
        'title_variants': [
            # Data
            'data', 'donnees', 'donn√©e',
            'database', 'base de donnees',
            
            # IA
            'ia', 'ai',
            'intelligence artificielle',
            'artificial intelligence',
            
            # ML
            'machine learning', 'ml',
            'deep learning', 'dl',
            
            # Big Data
            'big data',
            
            # Analytics
            'analytics', 'analytique',
            'analyse de donnees', 'analyse donnees'
        ],
        
        'keywords_title': [
            'data', 'donnees', 'donn√©e',
            'ia', 'ai',
            'machine learning', 'ml',
            'analytics', 'analytique',
            'big data'
        ],
        
        # Pas de filtre sur description/comp√©tences
        'keywords_strong': [],
        
        'competences_core': [],
        
        'competences_tech': [],
        
        # ‚úÖ POIDS ULTRA-PERMISSIF (presque tout sur titre)
        'weights': {
            'title': 0.9,        # 90% titre
            'description': 0.05,
            'competences': 0.05
        }
    }
}


# ============================================
# FONCTIONS UTILITAIRES
# ============================================

def get_profil_config(profil_name):
    if profil_name not in PROFILS:
        raise ValueError(f"Profil '{profil_name}' non trouv√©")
    return PROFILS[profil_name]


def get_all_profils():
    return list(PROFILS.keys())


def get_min_score(profil_name):
    """Retourne seuil minimum pour un profil"""
    
    # ‚úÖ Profil fourre-tout : seuil TR√àS BAS
    if profil_name == 'Data/IA - Non sp√©cifi√©':
        return 1.5
    
    # Profils stricts
    if profil_name in STRICT_PROFILES:
        return 5.0
    
    # Profils permissifs
    elif profil_name in PERMISSIVE_PROFILES:
        return 4.0
    
    # D√©faut
    else:
        return CLASSIFICATION_CONFIG['min_score']


def export_profils_json(filepath):
    import json
    
    export_data = {
        'version': 'v2_with_catch_all',
        'config': CLASSIFICATION_CONFIG,
        'strict_profiles': STRICT_PROFILES,
        'permissive_profiles': PERMISSIVE_PROFILES,
        'profils': PROFILS
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Profils v2 export√©s: {filepath}")


if __name__ == "__main__":
    print("="*70)
    print("üìã VALIDATION D√âFINITIONS PROFILS v2 (avec fourre-tout)")
    print("="*70)
    
    print(f"\n‚úÖ Version: v2 FINALE")
    print(f"‚úÖ Nombre de profils: {len(PROFILS)}")
    print(f"‚úÖ Min score global: {CLASSIFICATION_CONFIG['min_score']}")
    print(f"‚úÖ Min confidence: {CLASSIFICATION_CONFIG['min_confidence']}")
    
    print("\nüìä Nouveaut√©s v2:")
    print("   ‚úÖ Profil #14: 'Data/IA - Non sp√©cifi√©' (fourre-tout)")
    print("   ‚úÖ Seuil profil fourre-tout: 1.5 (ultra-permissif)")
    print("   ‚úÖ Poids profil fourre-tout: 90% titre")
    print("   ‚úÖ Capture tout ce qui contient 'data', 'ia', 'ml', etc.")
    
    print("\n‚úÖ Validation termin√©e !")
    print("\nüìä R√©sultat attendu:")
    print("   ‚úÖ Taux classification: 85-90%")
    print("   ‚úÖ Profils 1-13: classification pr√©cise (60-65%)")
    print("   ‚úÖ Profil #14: capture reste Data/IA (20-25%)")


# ============================================
# VALIDATION
# ============================================

if __name__ == "__main__":
    print("="*70)
    print("üìã VALIDATION D√âFINITIONS PROFILS v5 ENRICHIE")
    print("="*70)
    
    print(f"\n‚úÖ Version: v5 - Base nettoy√©e + enrichissements FR")
    print(f"‚úÖ Nombre de profils: {len(PROFILS)}")
    print(f"‚úÖ Min score global: {CLASSIFICATION_CONFIG['min_score']}")
    
    print("\nüìä Nouveaut√©s v5:")
    print("   ‚úÖ NOUVEAU profil: Data Manager (25 variants)")
    print("   ‚úÖ Data Engineer: + Big Data, Architecte Data, D√©veloppeur Data")
    print("   ‚úÖ Data Scientist: + Statisticien")
    print("   ‚úÖ BI Analyst: + D√©veloppeur BI, Analyste d√©cisionnel")
    
    print("\nüìã Liste des profils:")
    for i, profil_name in enumerate(PROFILS.keys(), 1):
        profil = PROFILS[profil_name]
        nb_variants = len(profil['title_variants'])
        min_score = get_min_score(profil_name)
        
        nouveau = " ‚≠ê NOUVEAU" if profil_name == "Data Manager" else ""
        enrichi = " üìà ENRICHI" if profil_name in ['Data Engineer', 'Data Scientist', 'BI Analyst'] else ""
        
        print(f"\n{i:2d}. {profil_name}{nouveau}{enrichi}")
        print(f"    {profil['description']}")
        print(f"    Variantes titre: {nb_variants}")
        print(f"    Score min: {min_score}/10")
    
    print("\n‚úÖ Validation termin√©e !")
    print("\nüìä R√©sultat attendu sur base nettoy√©e:")
    print("   ‚úÖ Taux classification: 70-80%")
    print("   ‚úÖ Data Manager capture: ~85 offres (Manager, Chef projet, CDO)")
    print("   ‚úÖ Data Engineer capture: + Big Data, Architecte Data")
    print("   ‚úÖ Vocabulaire FR enrichi")
# """
# D√©finitions des Profils M√©tier - Classification Hybride
# 12 profils Data/IA avec keywords, comp√©tences et param√®tres de scoring

# Auteur: Projet NLP Text Mining
# Date: D√©cembre 2025
# """

# # Configuration globale
# CLASSIFICATION_CONFIG = {
#     'min_score': 4.0,           # Score minimum pour classifier
#     'min_confidence': 0.6,      # Confiance minimum
#     'required_keywords': 1,     # Nb keywords required minimum
#     'default_weights': {
#         'rules': 0.3,           # Poids r√®gles
#         'tfidf': 0.4,           # Poids ML
#         'competences': 0.3      # Poids comp√©tences
#     }
# }

# # Profils stricts (score min plus √©lev√©)
# STRICT_PROFILES = [
#     'AI Engineer',
#     'AI Research Scientist',
#     'Computer Vision Engineer'
# ]

# # Profils permissifs (score min plus bas)
# PERMISSIVE_PROFILES = [
#     'Data Analyst',
#     'Data Consultant'
# ]


# # ============================================
# # D√âFINITION DES 12 PROFILS
# # ============================================

# PROFILS = {
    
#     # ========================================
#     # 1. DATA SCIENTIST
#     # ========================================
#     'Data Scientist': {
#         'description': 'ML classique, statistiques, mod√®les pr√©dictifs',
        
#         'keywords_required': [
#             'data scientist', 'data science',
#             'machine learning', 'apprentissage automatique',
#             'mod√®le pr√©dictif', 'mod√©lisation'
#         ],
        
#         'keywords_strong': [
#             'scikit-learn', 'sklearn',
#             'statistiques', 'statistics',
#             'r√©gression', 'classification',
#             'pr√©diction', 'prediction',
#             'analyse pr√©dictive',
#             'xgboost', 'lightgbm',
#             'features engineering',
#             'data mining',
#             'clustering', 'segmentation'
#         ],
        
#         'competences_core': [
#             'machine learning', 'python', 'scikit-learn',
#             'statistiques', 'r', 'data science'
#         ],
        
#         'competences_tech': [
#             'pandas', 'numpy', 'jupyter',
#             'matplotlib', 'seaborn', 'plotly',
#             'sql', 'git'
#         ],
        
#         'exclude_keywords': [
#             'llm', 'gpt', 'transformers',  # ‚Üí AI Engineer
#             'tableau', 'power bi',          # ‚Üí BI Analyst
#             'airflow', 'kafka', 'pipeline'  # ‚Üí Data Engineer
#         ],
        
#         'weights': {
#             'rules': 0.3,
#             'tfidf': 0.4,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 2. AI ENGINEER
#     # ========================================
#     'AI Engineer': {
#         'description': 'IA g√©n√©rative, LLMs, NLP avanc√©, transformers',
        
#         'keywords_required': [
#             'intelligence artificielle',
#             'llm', 'llms', 'large language model',
#             'gpt', 'bert', 'transformers'
#         ],
        
#         'keywords_strong': [
#             'langchain', 'llamaindex',
#             'rag', 'retrieval augmented generation',
#             'prompt engineering',
#             'fine-tuning', 'fine tuning',
#             'hugging face', 'huggingface',
#             'openai', 'anthropic', 'claude',
#             'generative ai', 'ia g√©n√©rative',
#             'chatbot', 'conversational ai',
#             'embedding', 'embeddings',
#             'vector database', 'pinecone', 'weaviate'
#         ],
        
#         'competences_core': [
#             'intelligence artificielle', 'llm', 'llms',
#             'transformers', 'gpt', 'bert',
#             'langchain', 'nlp'
#         ],
        
#         'competences_tech': [
#             'python', 'pytorch', 'tensorflow',
#             'hugging face', 'api', 'rest'
#         ],
        
#         'exclude_keywords': [
#             'scikit-learn',  # ‚Üí Data Scientist
#             'tableau', 'power bi',  # ‚Üí BI Analyst
#         ],
        
#         'weights': {
#             'rules': 0.4,      # Plus de poids sur r√®gles (profil √©mergent)
#             'tfidf': 0.3,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 3. ML ENGINEER
#     # ========================================
#     'ML Engineer': {
#         'description': 'MLOps, d√©ploiement ML, production, pipelines ML',
        
#         'keywords_required': [
#             'ml engineer', 'machine learning engineer',
#             'mlops', 'ml ops',
#             'd√©ploiement', 'deployment',
#             'production ml'
#         ],
        
#         'keywords_strong': [
#             'mlflow', 'kubeflow',
#             'model deployment', 'model serving',
#             'api ml', 'rest api',
#             'containerization', 'conteneurisation',
#             'monitoring ml', 'model monitoring',
#             'ci/cd ml', 'cicd',
#             'feature store',
#             'model registry',
#             'a/b testing',
#             'model versioning'
#         ],
        
#         'competences_core': [
#             'mlops', 'ci/cd', 'kubernetes', 'docker',
#             'machine learning', 'python'
#         ],
        
#         'competences_tech': [
#             'mlflow', 'kubeflow', 'tensorflow',
#             'pytorch', 'git', 'linux'
#         ],
        
#         'exclude_keywords': [
#             'llm', 'gpt',  # ‚Üí AI Engineer
#             'airflow',     # ‚Üí Data Engineer (sauf si ML aussi)
#         ],
        
#         'weights': {
#             'rules': 0.3,
#             'tfidf': 0.4,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 4. DATA ENGINEER
#     # ========================================
#     'Data Engineer': {
#         'description': 'Pipelines donn√©es, ETL, data warehousing, cloud',
        
#         'keywords_required': [
#             'data engineer', 'ing√©nieur donn√©es',
#             'pipeline', 'etl',
#             'data warehouse', 'entrep√¥t donn√©es'
#         ],
        
#         'keywords_strong': [
#             'airflow', 'kafka', 'spark',
#             'hadoop', 'hive',
#             'data lake', 'lakehouse',
#             'dbt', 'data build tool',
#             'streaming', 'batch processing',
#             'orchestration', 'orchestrateur',
#             'data integration',
#             'data ingestion',
#             'cloud data platform'
#         ],
        
#         'competences_core': [
#             'sql', 'python', 'airflow', 'spark',
#             'aws', 'data engineer'
#         ],
        
#         'competences_tech': [
#             'kafka', 'docker', 'kubernetes',
#             'postgresql', 'mongodb', 'redis'
#         ],
        
#         'exclude_keywords': [
#             'tableau', 'power bi',  # ‚Üí BI Analyst
#             'scikit-learn',         # ‚Üí Data Scientist
#         ],
        
#         'weights': {
#             'rules': 0.3,
#             'tfidf': 0.4,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 5. ANALYTICS ENGINEER
#     # ========================================
#     'Analytics Engineer': {
#         'description': 'Transformation donn√©es, dbt, SQL avanc√©, analytics',
        
#         'keywords_required': [
#             'analytics engineer',
#             'dbt', 'data build tool',
#             'transformation donn√©es'
#         ],
        
#         'keywords_strong': [
#             'sql avanc√©', 'advanced sql',
#             'data modeling', 'mod√©lisation donn√©es',
#             'data transformation',
#             'looker', 'metabase',
#             'analytics',
#             'business intelligence',
#             'data quality',
#             'data testing',
#             'version control sql'
#         ],
        
#         'competences_core': [
#             'dbt', 'sql', 'python',
#             'data modeling'
#         ],
        
#         'competences_tech': [
#             'git', 'postgresql', 'snowflake',
#             'databricks', 'looker'
#         ],
        
#         'exclude_keywords': [
#             'machine learning',  # ‚Üí Data Scientist
#             'airflow', 'kafka',  # ‚Üí Data Engineer
#         ],
        
#         'weights': {
#             'rules': 0.35,
#             'tfidf': 0.35,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 6. BI ANALYST
#     # ========================================
#     'BI Analyst': {
#         'description': 'Business Intelligence, dashboards, reporting, visualisation',
        
#         'keywords_required': [
#             'bi analyst', 'business intelligence',
#             'tableau', 'power bi',
#             'dashboard', 'reporting'
#         ],
        
#         'keywords_strong': [
#             'looker', 'qlik', 'metabase',
#             'visualisation donn√©es', 'data visualization',
#             'kpi', 'metrics',
#             'rapport', 'report',
#             'tableau de bord',
#             'business analyst',
#             'd√©cisionnel',
#             'dataviz'
#         ],
        
#         'competences_core': [
#             'power bi', 'tableau', 'sql',
#             'excel', 'looker'
#         ],
        
#         'competences_tech': [
#             'dax', 'powerquery', 'qlik',
#             'sql', 'excel'
#         ],
        
#         'exclude_keywords': [
#             'machine learning',  # ‚Üí Data Scientist
#             'python', 'airflow', # ‚Üí Data Engineer
#         ],
        
#         'weights': {
#             'rules': 0.4,
#             'tfidf': 0.3,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 7. MLOPS ENGINEER
#     # ========================================
#     'MLOps Engineer': {
#         'description': 'DevOps pour ML, CI/CD ML, infrastructure ML',
        
#         'keywords_required': [
#             'mlops', 'ml ops',
#             'devops ml', 'ml devops'
#         ],
        
#         'keywords_strong': [
#             'kubernetes', 'docker',
#             'ci/cd', 'cicd',
#             'terraform', 'infrastructure as code',
#             'monitoring ml', 'observability',
#             'gitlab ci', 'github actions',
#             'model serving',
#             'scalability ml',
#             'cloud infrastructure'
#         ],
        
#         'competences_core': [
#             'mlops', 'kubernetes', 'docker',
#             'ci/cd', 'devops'
#         ],
        
#         'competences_tech': [
#             'terraform', 'git', 'linux',
#             'aws', 'azure', 'gcp'
#         ],
        
#         'exclude_keywords': [],
        
#         'weights': {
#             'rules': 0.4,
#             'tfidf': 0.3,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 8. AI RESEARCH SCIENTIST
#     # ========================================
#     'AI Research Scientist': {
#         'description': 'Recherche IA, publications, PhD, innovation',
        
#         'keywords_required': [
#             'research scientist', 'chercheur',
#             'recherche', 'research',
#             'phd', 'doctorat'
#         ],
        
#         'keywords_strong': [
#             'publication', 'paper',
#             'conference', 'neurips', 'icml', 'iclr',
#             'innovation',
#             'state-of-the-art', 'sota',
#             'novel algorithm',
#             'academic',
#             'thesis', 'th√®se',
#             'arxiv'
#         ],
        
#         'competences_core': [
#             'recherche', 'intelligence artificielle',
#             'machine learning', 'deep learning'
#         ],
        
#         'competences_tech': [
#             'python', 'pytorch', 'tensorflow',
#             'jupyter', 'git'
#         ],
        
#         'exclude_keywords': [
#             'production', 'deployment',  # ‚Üí ML Engineer
#             'dashboard', 'reporting',    # ‚Üí BI Analyst
#         ],
        
#         'weights': {
#             'rules': 0.5,  # Tr√®s sp√©cifique
#             'tfidf': 0.3,
#             'competences': 0.2
#         }
#     },
    
#     # ========================================
#     # 9. COMPUTER VISION ENGINEER
#     # ========================================
#     'Computer Vision Engineer': {
#         'description': 'Vision par ordinateur, images, vid√©o, CNN',
        
#         'keywords_required': [
#             'computer vision', 'vision par ordinateur',
#             'image processing', 'traitement image',
#             'cnn', 'convolutional'
#         ],
        
#         'keywords_strong': [
#             'opencv', 'yolo', 'mask r-cnn',
#             'object detection', 'd√©tection objet',
#             'segmentation image',
#             'face recognition', 'reconnaissance faciale',
#             'video analysis',
#             'image classification',
#             'deep learning vision',
#             'resnet', 'vgg', 'inception'
#         ],
        
#         'competences_core': [
#             'computer vision', 'deep learning',
#             'opencv', 'pytorch', 'tensorflow'
#         ],
        
#         'competences_tech': [
#             'python', 'opencv', 'cuda',
#             'gpu', 'docker'
#         ],
        
#         'exclude_keywords': [
#             'nlp', 'text',  # ‚Üí AI Engineer / NLP
#             'tableau',      # ‚Üí BI Analyst
#         ],
        
#         'weights': {
#             'rules': 0.5,  # Tr√®s sp√©cifique
#             'tfidf': 0.3,
#             'competences': 0.2
#         }
#     },
    
#     # ========================================
#     # 10. DATA ANALYST
#     # ========================================
#     'Data Analyst': {
#         'description': 'Analyse exploratoire, SQL, Excel, reporting simple',
        
#         'keywords_required': [
#             'data analyst', 'analyste donn√©es',
#             'analyse donn√©es', 'data analysis'
#         ],
        
#         'keywords_strong': [
#             'excel', 'google sheets',
#             'sql', 'query',
#             'analyse exploratoire', 'exploratory analysis',
#             'statistiques descriptives',
#             'rapport', 'reporting',
#             'data cleaning',
#             'data entry',
#             'spreadsheet'
#         ],
        
#         'competences_core': [
#             'sql', 'excel', 'analyse',
#             'python'
#         ],
        
#         'competences_tech': [
#             'pandas', 'sql', 'excel',
#             'power bi', 'tableau'
#         ],
        
#         'exclude_keywords': [
#             'machine learning',  # ‚Üí Data Scientist
#             'airflow', 'kafka',  # ‚Üí Data Engineer
#         ],
        
#         'weights': {
#             'rules': 0.25,  # Profil large
#             'tfidf': 0.45,
#             'competences': 0.3
#         }
#     },
    
#     # ========================================
#     # 11. DATA ARCHITECT
#     # ========================================
#     'Data Architect': {
#         'description': 'Architecture donn√©es, gouvernance, strat√©gie',
        
#         'keywords_required': [
#             'data architect', 'architecte donn√©es',
#             'architecture donn√©es', 'data architecture'
#         ],
        
#         'keywords_strong': [
#             'gouvernance', 'governance',
#             'data strategy', 'strat√©gie donn√©es',
#             'enterprise architecture',
#             'data modeling', 'mod√©lisation',
#             'master data management', 'mdm',
#             'metadata management',
#             'data catalog',
#             'data quality',
#             'data lineage'
#         ],
        
#         'competences_core': [
#             'architecture', 'gouvernance',
#             'data modeling', 'sql'
#         ],
        
#         'competences_tech': [
#             'sql', 'cloud', 'aws', 'azure',
#             'databricks', 'snowflake'
#         ],
        
#         'exclude_keywords': [
#             'junior', 'stage',  # ‚Üí Senior role
#         ],
        
#         'weights': {
#             'rules': 0.4,
#             'tfidf': 0.35,
#             'competences': 0.25
#         }
#     },
    
#     # ========================================
#     # 12. DATA CONSULTANT
#     # ========================================
#     'Data Consultant': {
#         'description': 'Conseil Data, transformation, accompagnement client',
        
#         'keywords_required': [
#             'consultant', 'conseil',
#             'consulting', 'advisory'
#         ],
        
#         'keywords_strong': [
#             'transformation', 'transformation digitale',
#             'accompagnement', 'accompagner',
#             'client', 'mission',
#             'conseil strat√©gique',
#             'change management',
#             'conduite changement',
#             'esn', 'ssii',
#             'cabinet conseil'
#         ],
        
#         'competences_core': [
#             'conseil', 'transformation',
#             'management', 'gestion projet'
#         ],
        
#         'competences_tech': [
#             'python', 'sql', 'excel',
#             'power bi', 'powerpoint'
#         ],
        
#         'exclude_keywords': [
#             'd√©veloppement', 'coding',  # ‚Üí Profils techniques
#         ],
        
#         'weights': {
#             'rules': 0.25,  # Profil large
#             'tfidf': 0.45,
#             'competences': 0.3
#         }
#     }
# }


# # ============================================
# # FONCTIONS UTILITAIRES
# # ============================================

# def get_profil_config(profil_name):
#     """R√©cup√®re la configuration d'un profil"""
#     if profil_name not in PROFILS:
#         raise ValueError(f"Profil '{profil_name}' non trouv√©")
#     return PROFILS[profil_name]


# def get_all_profils():
#     """Retourne la liste de tous les profils"""
#     return list(PROFILS.keys())


# def get_min_score(profil_name):
#     """Retourne le score minimum pour un profil"""
#     if profil_name in STRICT_PROFILES:
#         return 5.0
#     elif profil_name in PERMISSIVE_PROFILES:
#         return 3.5
#     else:
#         return CLASSIFICATION_CONFIG['min_score']


# def export_profils_json(filepath):
#     """Exporte les profils en JSON"""
#     import json
    
#     export_data = {
#         'config': CLASSIFICATION_CONFIG,
#         'strict_profiles': STRICT_PROFILES,
#         'permissive_profiles': PERMISSIVE_PROFILES,
#         'profils': PROFILS
#     }
    
#     with open(filepath, 'w', encoding='utf-8') as f:
#         json.dump(export_data, f, ensure_ascii=False, indent=2)
    
#     print(f"‚úÖ Profils export√©s: {filepath}")


# # ============================================
# # VALIDATION
# # ============================================

# if __name__ == "__main__":
#     print("="*70)
#     print("üìã VALIDATION D√âFINITIONS PROFILS")
#     print("="*70)
    
#     print(f"\n‚úÖ Nombre de profils d√©finis: {len(PROFILS)}")
#     print(f"‚úÖ Profils stricts: {len(STRICT_PROFILES)}")
#     print(f"‚úÖ Profils permissifs: {len(PERMISSIVE_PROFILES)}")
    
#     print("\nüìã Liste des profils:")
#     for i, profil_name in enumerate(PROFILS.keys(), 1):
#         profil = PROFILS[profil_name]
#         nb_keywords_req = len(profil['keywords_required'])
#         nb_keywords_strong = len(profil['keywords_strong'])
#         nb_comp_core = len(profil['competences_core'])
        
#         print(f"\n{i:2d}. {profil_name}")
#         print(f"    Description: {profil['description']}")
#         print(f"    Keywords required: {nb_keywords_req}")
#         print(f"    Keywords strong: {nb_keywords_strong}")
#         print(f"    Comp√©tences core: {nb_comp_core}")
#         print(f"    Score min: {get_min_score(profil_name)}")
    
#     print("\n‚úÖ Validation termin√©e !")