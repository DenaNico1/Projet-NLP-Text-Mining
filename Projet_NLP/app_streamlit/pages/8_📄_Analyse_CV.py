"""Page 8 : Analyse de CV
Upload CV â†’ Extraction compÃ©tences â†’ Recommandation offres
"""

import streamlit as st
import sys
from pathlib import Path
import pandas as pd
import json
import pickle
import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent / "utils"))
from data_loader import load_preprocessed_data
from search_utils import (
    extract_competences_from_cv,
    recommend_offers_by_cv,
    compute_gap_analysis,
    estimate_salary_impact
)

st.set_page_config(page_title="Analyse CV", page_icon="ğŸ“„", layout="wide")

# Titre
st.title("ğŸ“„ Analyse de CV & Recommandations")
st.markdown("Analysez votre CV et obtenez des recommandations d'offres personnalisÃ©es")

# Chargement donnÃ©es
try:
    df = load_preprocessed_data()
    
    # Charger dictionnaire compÃ©tences
    dict_path = Path(__file__).parent.parent.parent / "resultats_nlp" / "dictionnaire_competences.json"
    with open(dict_path, 'r', encoding='utf-8') as f:
        dict_comp = json.load(f)['competences']
    
    # Charger modÃ¨le de classification
    model_path = Path(__file__).parent.parent.parent / "resultats_nlp" / "models" / "model_svm.pkl"
    vectorizer_path = Path(__file__).parent.parent.parent / "resultats_nlp" / "models" / "vectorizer_classification.pkl"
    
    with open(model_path, 'rb') as f:
        model_classif = pickle.load(f)
    
    with open(vectorizer_path, 'rb') as f:
        vectorizer_classif = pickle.load(f)
    
    # Charger compÃ©tences signature
    chi2_path = Path(__file__).parent.parent.parent / "resultats_nlp" / "chi2_selection.json"
    with open(chi2_path, 'r', encoding='utf-8') as f:
        chi2_data = json.load(f)
        signature_by_profile = chi2_data['signature_by_profile']
    
    # Charger donnÃ©es salariales
    sal_path = Path(__file__).parent.parent.parent / "resultats_nlp" / "stacks_salaires.json"
    with open(sal_path, 'r', encoding='utf-8') as f:
        sal_data = json.load(f)
        salary_by_comp = {
            item['competence']: item['salary_median']
            for item in sal_data.get('salaire_par_competence', [])
        }
    
except Exception as e:
    st.error(f"âŒ Erreur chargement : {e}")
    st.stop()

# ============================================================================
# INPUT : CV
# ============================================================================

st.markdown("## ğŸ“ Votre CV")

# MÃ©thode 1 : Copier-coller le texte
cv_text = st.text_area(
    "Collez le texte de votre CV ici",
    height=300,
    placeholder="""Exemple :
Data Scientist avec 3 ans d'expÃ©rience en Machine Learning.

CompÃ©tences :
- Python, TensorFlow, PyTorch
- SQL, Pandas, NumPy
- Docker, Kubernetes
- AWS

ExpÃ©rience :
- DÃ©veloppement de modÃ¨les de recommandation
- DÃ©ploiement de modÃ¨les en production
- ...
""",
    help="Copiez-collez le contenu de votre CV (texte brut)"
)

# Bouton d'analyse
if st.button("ğŸ” Analyser mon CV", type="primary", disabled=not cv_text):
    
    with st.spinner("ğŸ”„ Analyse en cours..."):
        
        # ====================================================================
        # Ã‰TAPE 1 : Extraction compÃ©tences
        # ====================================================================
        
        st.markdown("---")
        st.markdown("## ğŸ“ CompÃ©tences Extraites")
        
        cv_competences = extract_competences_from_cv(cv_text, dict_comp)
        
        if not cv_competences:
            st.warning("âš ï¸ Aucune compÃ©tence reconnue dans le CV. Essayez d'ajouter plus de dÃ©tails.")
            st.stop()
        
        st.success(f"âœ… {len(cv_competences)} compÃ©tences extraites")
        
        # Afficher les compÃ©tences
        cols = st.columns(4)
        for i, comp in enumerate(sorted(cv_competences)):
            cols[i % 4].markdown(f"âœ… {comp}")
        
        # ====================================================================
        # Ã‰TAPE 2 : Classification du profil
        # ====================================================================
        
        st.markdown("---")
        st.markdown("## ğŸ¯ Profil DÃ©tectÃ©")
        
        # Vectoriser le CV
        cv_vec = vectorizer_classif.transform([cv_text])
        
        # PrÃ©dire le profil
        profil_pred = model_classif.predict(cv_vec)[0]
        
        # ProbabilitÃ©s (si SVM avec probability=True)
        try:
            probas = model_classif.predict_proba(cv_vec)[0]
            classes = model_classif.classes_
            
            # Trier par probabilitÃ© dÃ©croissante
            top_indices = np.argsort(probas)[::-1]
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.metric(
                    "Profil Principal",
                    profil_pred,
                    f"{probas[top_indices[0]]*100:.0f}% confiance"
                )
            
            with col2:
                st.markdown("**ProbabilitÃ©s par profil :**")
                df_probas = pd.DataFrame({
                    'Profil': [classes[i] for i in top_indices],
                    'ProbabilitÃ©': [probas[i] * 100 for i in top_indices]
                })
                st.dataframe(df_probas, hide_index=True, use_container_width=True)
        
        except:
            # Si pas de probabilitÃ©s disponibles
            st.metric("Profil DÃ©tectÃ©", profil_pred)
        
        # ====================================================================
        # Ã‰TAPE 3 : Gap Analysis
        # ====================================================================
        
        st.markdown("---")
        st.markdown("## ğŸ’¡ Gap Analysis")
        
        gap = compute_gap_analysis(cv_competences, profil_pred, signature_by_profile)
        
        st.info(gap['message'])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### âœ… CompÃ©tences MaÃ®trisÃ©es")
            if gap['competences_present']:
                for comp in gap['competences_present'][:10]:
                    st.markdown(f"- {comp}")
                if len(gap['competences_present']) > 10:
                    st.markdown(f"*... et {len(gap['competences_present']) - 10} autres*")
            else:
                st.write("Aucune compÃ©tence signature identifiÃ©e")
        
        with col2:
            st.markdown("### âŒ CompÃ©tences Manquantes")
            if gap['competences_missing']:
                for comp in gap['competences_missing'][:10]:
                    st.markdown(f"- {comp}")
                if len(gap['competences_missing']) > 10:
                    st.markdown(f"*... et {len(gap['competences_missing']) - 10} autres*")
                
                # Estimation impact salarial
                salary_impact = estimate_salary_impact(gap['competences_missing'], salary_by_comp)
                
                if salary_impact['potential_increase_pct'] > 0:
                    st.success(f"ğŸ’° {salary_impact['message']}")
            else:
                st.write("âœ… Vous maÃ®trisez toutes les compÃ©tences signature !")
        
        # ====================================================================
        # Ã‰TAPE 4 : Recommandation d'offres
        # ====================================================================
        
        st.markdown("---")
        st.markdown("## ğŸ† Offres RecommandÃ©es")
        
        # Recommandation basÃ©e sur compÃ©tences
        recommendations = recommend_offers_by_cv(
            df=df,
            cv_competences=cv_competences,
            embeddings_cv=None,  # Pas d'embeddings pour version simple
            embeddings_offres=None,
            top_k=10,
            method='competences'
        )
        
        st.success(f"âœ… {len(recommendations)} offres recommandÃ©es")
        
        # Afficher les offres
        for idx, row in recommendations.iterrows():
            score_pct = row['recommendation_score'] * 100
            
            # Couleur selon le score
            if score_pct >= 80:
                icon = "ğŸŸ¢"
            elif score_pct >= 60:
                icon = "ğŸŸ¡"
            else:
                icon = "ğŸŸ "
            
            with st.expander(f"{icon} **{row['title']}** - {row['company_name']} ({score_pct:.0f}% match)"):
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.markdown("**ğŸ“ Lieu**")
                    if pd.notna(row['city']):
                        st.write(row['city'])
                    else:
                        st.write("Non spÃ©cifiÃ©")
                
                with col2:
                    st.markdown("**ğŸ“ Contrat**")
                    st.write(row['contract_type'] if pd.notna(row['contract_type']) else "N/A")
                
                with col3:
                    st.markdown("**ğŸ¯ Profil**")
                    st.write(row['profil'] if pd.notna(row['profil']) else "N/A")
                
                with col4:
                    st.markdown("**ğŸ’° Salaire**")
                    if pd.notna(row['salary_annual']):
                        st.write(f"{row['salary_annual']/1000:.0f}kâ‚¬")
                    else:
                        st.write("N/A")
                
                # CompÃ©tences
                st.markdown("**ğŸ“ CompÃ©tences demandÃ©es**")
                
                offre_comps = row['competences_found']
                
                # CompÃ©tences que vous avez
                comps_you_have = [c for c in offre_comps if c in cv_competences]
                # CompÃ©tences que vous n'avez pas
                comps_you_need = [c for c in offre_comps if c not in cv_competences]
                
                if comps_you_have:
                    st.markdown("âœ… **Vous avez** : " + ", ".join(comps_you_have))
                
                if comps_you_need:
                    st.markdown("âŒ **Ã€ acquÃ©rir** : " + ", ".join(comps_you_need[:5]))
                    if len(comps_you_need) > 5:
                        st.markdown(f"*... et {len(comps_you_need) - 5} autres*")
                
                # Lien
                if pd.notna(row.get('url')):
                    st.markdown(f"[ğŸ”— Voir l'offre]({row['url']})")
        
        # Export
        st.markdown("---")
        if st.button("ğŸ“¥ Exporter les recommandations en CSV"):
            csv = recommendations.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="â¬‡ï¸ TÃ©lÃ©charger CSV",
                data=csv,
                file_name="recommandations_cv.csv",
                mime="text/csv"
            )

else:
    # Message initial
    st.info("ğŸ‘† Collez le texte de votre CV ci-dessus et cliquez sur 'Analyser mon CV'")
    
    # Guide
    st.markdown("### ğŸ’¡ Guide d'Utilisation")
    
    st.markdown("""
    **Comment Ã§a marche ?**
    
    1. **Copiez votre CV** (format texte)
    2. **Collez-le** dans la zone de texte ci-dessus
    3. **Cliquez sur 'Analyser'**
    
    **Ce que vous obtiendrez :**
    
    - âœ… Extraction automatique de vos compÃ©tences
    - ğŸ¯ DÃ©tection de votre profil mÃ©tier
    - ğŸ’¡ Analyse des compÃ©tences manquantes
    - ğŸ’° Estimation de l'impact salarial
    - ğŸ† Top 10 offres qui vous correspondent
    
    **Conseils :**
    
    - Incluez vos **compÃ©tences techniques** (Python, SQL, Docker...)
    - Mentionnez vos **projets** et **rÃ©alisations**
    - Indiquez votre **expÃ©rience** (annÃ©es, contexte)
    - Plus le CV est dÃ©taillÃ©, meilleure sera l'analyse !
    """)
    
    # Exemple
    with st.expander("ğŸ“‹ Voir un exemple de CV"):
        st.code("""
Data Scientist Senior
5 ans d'expÃ©rience

COMPÃ‰TENCES TECHNIQUES
- Langages : Python, R, SQL
- ML/DL : TensorFlow, PyTorch, Scikit-learn, XGBoost
- Data : Pandas, NumPy, Spark
- DevOps : Docker, Kubernetes, Git
- Cloud : AWS (SageMaker, Lambda), Azure
- BI : Power BI, Tableau

EXPÃ‰RIENCE
Data Scientist Senior - Startup FinTech (2020-2024)
- DÃ©veloppement de modÃ¨les de dÃ©tection de fraude (XGBoost, recall 95%)
- DÃ©ploiement de 15 modÃ¨les en production (Docker + Kubernetes)
- Mise en place pipeline MLOps (Airflow + MLflow)

Machine Learning Engineer - Grande Entreprise (2018-2020)
- CrÃ©ation systÃ¨me de recommandation (collaborative filtering)
- Optimisation modÃ¨les NLP (BERT fine-tuning)
- Mentoring 3 data scientists juniors

PROJETS
- Chatbot NLP pour support client (GPT-3 + LangChain)
- PrÃ©diction churn clients (feature engineering avancÃ©)
        """, language="text")